{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_links(file_path):\n",
    "    # Read all the links from the file\n",
    "    with open(file_path, 'r') as f:\n",
    "        links = f.readlines()\n",
    "\n",
    "    # Remove the newline character from the end of each link\n",
    "    links = [link.strip() for link in links]\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "    # Get the title of the page\n",
    "    title = soup.title.string\n",
    "    # Remove the \" - MachineLearningMastery.com\" from the title\n",
    "    title = title[:-29]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_published_date(soup):\n",
    "    # Get date from \"article:published_time\" meta tag\n",
    "    date = soup.find(\"meta\", property=\"article:published_time\")['content']\n",
    "    # Convert the date to a more readable format\n",
    "    date = date[:10]\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_advertisement(soup):\n",
    "    blocks = []\n",
    "\n",
    "    # Find the button with specific data attributes\n",
    "    buttons = soup.find_all(\n",
    "        'button', attrs={'data-leadbox-domain': 'machinelearningmastery.lpages.co'})\n",
    "\n",
    "    for button in buttons:\n",
    "        # Find the parent of the button, which is the <center> block\n",
    "        # This will select the entire <center> block\n",
    "        blocks.append(button.find_parent('center'))\n",
    "\n",
    "    # Find the books advertisements\n",
    "    books = soup.find_all(\n",
    "        'a', attrs={'href': \"/deep-learning-for-computer-vision/\"})\n",
    "    for book in books:\n",
    "        blocks.append(book.find_parent(class_='widget_text awac-wrapper'))\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_selection(tag):\n",
    "    if tag.name == \"p\" or tag.name == \"li\" or tag.name == \"h2\":\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_content(content):\n",
    "    formatted_content = []\n",
    "    for i in range(len(content)):\n",
    "        text_block = content[i].get_text()\n",
    "        if text_block == \"Comment * \":\n",
    "            break\n",
    "        if content[i].name == \"li\":\n",
    "            text_block = \"- \" + text_block\n",
    "        if content[i].name == \"h2\":\n",
    "            text_block = \"# \" + text_block\n",
    "        formatted_content.append(text_block)\n",
    "    # Convert the content to a string\n",
    "    formatted_content = \"\\n\".join(formatted_content)\n",
    "    return formatted_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(soup):\n",
    "    # Get content from the article\n",
    "    base_content = soup.find(class_=\"col-full\", id=\"content\")\n",
    "    # Remove the id=\"comments\" div from the content\n",
    "    for div in base_content.find_all(\"div\", id='comments'):\n",
    "        div.decompose()\n",
    "\n",
    "    # Remove the advertisements from the content\n",
    "    advertisements = find_advertisement(soup)\n",
    "    if len(advertisements) > 0:\n",
    "        for advertisement in advertisements:\n",
    "            if type(advertisement) is not type(None):\n",
    "                advertisement.decompose()\n",
    "\n",
    "    # Remove related articles from the content\n",
    "    related_articles = base_content.find_all(\"div\", class_=\"crp_related\")\n",
    "    for related_article in related_articles:\n",
    "        related_article.decompose()\n",
    "\n",
    "    # Filter only the paragraphs\n",
    "    content = base_content.find_all(custom_selection)\n",
    "    formatted_content = format_content(content)\n",
    "    return formatted_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_block(soup):\n",
    "    # Find the <textarea> element by its class name\n",
    "    textarea = soup.find_all('textarea', class_=\"urvanov-syntax-highlighter-plain\")\n",
    "\n",
    "    text_content = []\n",
    "    # Extract the text content\n",
    "    for i in range(len(textarea)):\n",
    "        code_content = textarea[i].get_text()\n",
    "        \n",
    "        # Strim the ... from start and end of the text if they exist\n",
    "        if code_content.startswith(\"...\"):\n",
    "            code_content = code_content[3:]\n",
    "\n",
    "        text_content.append(code_content)\n",
    "\n",
    "    formatted_content = \"\\n\".join(text_content)\n",
    "    return \"'''\\n\" + formatted_content + \"\\n'''\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_url(urls, delay=0):\n",
    "    dr = webdriver.Edge()\n",
    "    meta_data = []\n",
    "    for i in range(len(urls)):\n",
    "        print(f\"Running url {i}\")\n",
    "        dr.get(urls[i])\n",
    "        soup = BeautifulSoup(dr.page_source, 'html.parser')\n",
    "\n",
    "        title = get_title(soup)\n",
    "        url = urls[i]\n",
    "        date = get_published_date(soup)\n",
    "        content = get_content(soup)\n",
    "        code_block = get_code_block(soup)\n",
    "\n",
    "        meta_data.append((title, url, date, content, code_block))\n",
    "        time.sleep(delay)\n",
    "    \n",
    "    dr.quit()\n",
    "\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_to_file(meta_data, base_path):\n",
    "    for i in range(len(meta_data)):\n",
    "        title, url, date, content, code_block = meta_data[i]\n",
    "        file_path = os.path.join(base_path, f\"{i}.txt\")\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(title + \"\\n\")\n",
    "            f.write(url + \"\\n\")\n",
    "            f.write(date + \"\\n\")\n",
    "            f.write(content + \"\\n\")\n",
    "            f.write(code_block + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1396"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running url 0\n",
      "Running url 1\n",
      "Running url 2\n",
      "Running url 3\n",
      "Running url 4\n",
      "Running url 5\n",
      "Running url 6\n",
      "Running url 7\n",
      "Running url 8\n",
      "Running url 9\n",
      "Running url 10\n",
      "Running url 11\n",
      "Running url 12\n",
      "Running url 13\n",
      "Running url 14\n",
      "Running url 15\n",
      "Running url 16\n",
      "Running url 17\n",
      "Running url 18\n",
      "Running url 19\n",
      "Running url 20\n",
      "Running url 21\n",
      "Running url 22\n",
      "Running url 23\n",
      "Running url 24\n",
      "Running url 25\n",
      "Running url 26\n",
      "Running url 27\n",
      "Running url 28\n",
      "Running url 29\n",
      "Running url 30\n",
      "Running url 31\n",
      "Running url 32\n",
      "Running url 33\n",
      "Running url 34\n",
      "Running url 35\n",
      "Running url 36\n",
      "Running url 37\n",
      "Running url 38\n",
      "Running url 39\n",
      "Running url 40\n",
      "Running url 41\n",
      "Running url 42\n",
      "Running url 43\n",
      "Running url 44\n",
      "Running url 45\n",
      "Running url 46\n",
      "Running url 47\n",
      "Running url 48\n",
      "Running url 49\n",
      "Running url 50\n",
      "Running url 51\n",
      "Running url 52\n",
      "Running url 53\n",
      "Running url 54\n",
      "Running url 55\n",
      "Running url 56\n",
      "Running url 57\n",
      "Running url 58\n",
      "Running url 59\n",
      "Running url 60\n",
      "Running url 61\n",
      "Running url 62\n",
      "Running url 63\n",
      "Running url 64\n",
      "Running url 65\n",
      "Running url 66\n",
      "Running url 67\n",
      "Running url 68\n",
      "Running url 69\n",
      "Running url 70\n",
      "Running url 71\n",
      "Running url 72\n",
      "Running url 73\n",
      "Running url 74\n",
      "Running url 75\n",
      "Running url 76\n",
      "Running url 77\n",
      "Running url 78\n",
      "Running url 79\n",
      "Running url 80\n",
      "Running url 81\n",
      "Running url 82\n",
      "Running url 83\n",
      "Running url 84\n",
      "Running url 85\n",
      "Running url 86\n",
      "Running url 87\n",
      "Running url 88\n",
      "Running url 89\n",
      "Running url 90\n",
      "Running url 91\n",
      "Running url 92\n",
      "Running url 93\n",
      "Running url 94\n",
      "Running url 95\n",
      "Running url 96\n",
      "Running url 97\n",
      "Running url 98\n",
      "Running url 99\n"
     ]
    }
   ],
   "source": [
    "batch = 10\n",
    "os.makedirs(f\"data/data{batch}/\", exist_ok=True)\n",
    "links = read_links(\"links.txt\")\n",
    "meta_data = get_data_from_url(links[batch * 100:batch * 100 + 100])\n",
    "write_data_to_file(meta_data, f\"data/data{batch}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = webdriver.Edge()\n",
    "dr.get(\"https://machinelearningmastery.com/introduction-to-1x1-convolutions-to-reduce-the-complexity-of-convolutional-neural-networks/\")\n",
    "soup = BeautifulSoup(dr.page_source, 'html.parser')\n",
    "with open(\"test.html\", 'w') as f:\n",
    "    f.write(soup.prettify())\n",
    "dr.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling can be used to down sample the content of feature maps, reducing their width and height whilst maintaining their salient features.\n",
      "A problem with deep convolutional neural networks is that the number of feature maps often increases with the depth of the network. This problem can result in a dramatic increase in the number of parameters and computation required when larger filter sizes are used, such as 5×5 and 7×7.\n",
      "To address this problem, a 1×1 convolutional layer can be used that offers a channel-wise pooling, often called feature map pooling or a projection layer. This simple technique can be used for dimensionality reduction, decreasing the number of feature maps whilst retaining their salient features. It can also be used directly to create a one-to-one projection of the feature maps to pool features across channels or to increase the number of feature maps, such as after traditional pooling layers.\n",
      "In this tutorial, you will discover how to use 1×1 filters to control the number of feature maps in a convolutional neural network.\n",
      "After completing this tutorial, you will know:\n",
      "- The 1×1 filter can be used to create a linear projection of a stack of feature maps.\n",
      "- The projection created by a 1×1 can act like channel-wise pooling and be used for dimensionality reduction.\n",
      "- The projection created by a 1×1 can also be used directly or be used to increase the number of feature maps in a model.\n",
      "Kick-start your project with my new book Deep Learning for Computer Vision, including step-by-step tutorials and the Python source code files for all examples.\n",
      "Let’s get started.\n",
      "A Gentle Introduction to 1×1 Convolutions to Reduce the Complexity of Convolutional Neural NetworksPhoto copyright, some rights reserved.\n",
      "# Tutorial Overview\n",
      "This tutorial is divided into five parts; they are:\n",
      "- Convolutions Over Channels\n",
      "- Problem of Too Many Feature Maps\n",
      "- Downsample Feature Maps With 1×1 Filters\n",
      "- Examples of How to Use 1×1 Convolutions\n",
      "- Examples of 1×1 Filters in CNN Model Architectures\n",
      "# Convolutions Over Channels\n",
      "Recall that a convolutional operation is a linear application of a smaller filter to a larger input that results in an output feature map.\n",
      "A filter applied to an input image or input feature map always results in a single number. The systematic left-to-right and top-to-bottom application of the filter to the input results in a two-dimensional feature map. One filter creates one corresponding feature map.\n",
      "A filter must have the same depth or number of channels as the input, yet, regardless of the depth of the input and the filter, the resulting output is a single number and one filter creates a feature map with a single channel.\n",
      "Let’s make this concrete with some examples:\n",
      "- If the input has one channel such as a grayscale image, then a 3×3 filter will be applied in 3x3x1 blocks.\n",
      "- If the input image has three channels for red, green, and blue, then a 3×3 filter will be applied in 3x3x3 blocks.\n",
      "- If the input is a block of feature maps from another convolutional or pooling layer and has the depth of 64, then the 3×3 filter will be applied in 3x3x64 blocks to create the single values to make up the single output feature map.\n",
      "The depth of the output of one convolutional layer is only defined by the number of parallel filters applied to the input.\n",
      "# Problem of Too Many Feature Maps\n",
      "The depth of the input or number of filters used in convolutional layers often increases with the depth of the network, resulting in an increase in the number of resulting feature maps. It is a common model design pattern.\n",
      "Further, some network architectures, such as the inception architecture, may also concatenate the output feature maps from multiple convolutional layers, which may also dramatically increase the depth of the input to subsequent convolutional layers.\n",
      "A large number of feature maps in a convolutional neural network can cause a problem as a convolutional operation must be performed down through the depth of the input. This is a particular problem if the convolutional operation being performed is relatively large, such as 5×5 or 7×7 pixels, as it can result in considerably more parameters (weights) and, in turn, computation to perform the convolutional operations (large space and time complexity).\n",
      "Pooling layers are designed to downscale feature maps and systematically halve the width and height of feature maps in the network. Nevertheless, pooling layers do not change the number of filters in the model, the depth, or number of channels.\n",
      "Deep convolutional neural networks require a corresponding pooling type of layer that can downsample or reduce the depth or number of feature maps.\n",
      "# Downsample Feature Maps With 1×1 Filters\n",
      "The solution is to use a 1×1 filter to down sample the depth or number of feature maps.\n",
      "A 1×1 filter will only have a single parameter or weight for each channel in the input, and like the application of any filter results in a single output value. This structure allows the 1×1 filter to act like a single neuron with an input from the same position across each of the feature maps in the input. This single neuron can then be applied systematically with a stride of one, left-to-right and top-to-bottom without any need for padding, resulting in a feature map with the same width and height as the input.\n",
      "The 1×1 filter is so simple that it does not involve any neighboring pixels in the input; it may not be considered a convolutional operation. Instead, it is a linear weighting or projection of the input. Further, a nonlinearity is used as with other convolutional layers, allowing the projection to perform non-trivial computation on the input feature maps.\n",
      "This simple 1×1 filter provides a way to usefully summarize the input feature maps. The use of multiple 1×1 filters, in turn, allows the tuning of the number of summaries of the input feature maps to create, effectively allowing the depth of the feature maps to be increased or decreased as needed.\n",
      "A convolutional layer with a 1×1 filter can, therefore, be used at any point in a convolutional neural network to control the number of feature maps. As such, it is often referred to as a projection operation or projection layer, or even a feature map or channel pooling layer.\n",
      "Now that we know that we can control the number of feature maps with 1×1 filters, let’s make it concrete with some examples.\n",
      "# Examples of How to Use 1×1 Convolutions\n",
      "We can make the use of a 1×1 filter concrete with some examples.\n",
      "Consider that we have a convolutional neural network that expected color images input with the square shape of 256x256x3 pixels.\n",
      "These images then pass through a first hidden layer with 512 filters, each with the size of 3×3 with the same padding, followed by a ReLU activation function.\n",
      "The example below demonstrates this simple model.\n",
      "Running the example creates the model and summarizes the model architecture.\n",
      "There are no surprises; the output of the first hidden layer is a block of feature maps with the three-dimensional shape of 256x256x512.\n",
      "\n",
      "A 1×1 filter can be used to create a projection of the feature maps.\n",
      "The number of feature maps created will be the same number and the effect may be a refinement of the features already extracted. This is often called channel-wise pooling, as opposed to traditional feature-wise pooling on each channel. It can be implemented as follows:\n",
      "We can see that we use the same number of features and still follow the application of the filter with a rectified linear activation function.\n",
      "The complete example is listed below.\n",
      "Running the example creates the model and summarizes the architecture.\n",
      "We can see that no change is made to the width or height of the feature maps, and by design, the number of feature maps is kept constant with a simple projection operation applied.\n",
      "\n",
      "The 1×1 filter can be used to decrease the number of feature maps.\n",
      "This is the most common application of this type of filter and in this way, the layer is often called a feature map pooling layer.\n",
      "In this example, we can decrease the depth (or channels) from 512 to 64. This might be useful if the subsequent layer we were going to add to our model would be another convolutional layer with 7×7 filters. These filters would only be applied at a depth of 64 rather than 512.\n",
      "The composition of the 64 feature maps is not the same as the original 512, but contains a useful summary of dimensionality reduction that captures the salient features, such that the 7×7 operation may have a similar effect on the 64 feature maps as it might have on the original 512.\n",
      "Further, a 7×7 convolutional layer with 64 filters itself applied to the 512 feature maps output by the first hidden layer would result in approximately one million parameters (weights). If the 1×1 filter is used to reduce the number of feature maps to 64 first, then the number of parameters required for the 7×7 layer is only approximately 200,000, an enormous difference.\n",
      "The complete example of using a 1×1 filter for dimensionality reduction is listed below.\n",
      "Running the example creates the model and summarizes its structure.\n",
      "We can see that the width and height of the feature maps are unchanged, yet the number of feature maps was reduced from 512 to 64.\n",
      "\n",
      "The 1×1 filter can be used to increase the number of feature maps.\n",
      "This is a common operation used after a pooling layer prior to applying another convolutional layer.\n",
      "The projection effect of the filter can be applied as many times as needed to the input, allowing the number of feature maps to be scaled up and yet have a composition that captures the salient features of the original.\n",
      "We can increase the number of feature maps from 512 input from the first hidden layer to double the size at 1,024 feature maps.\n",
      "The complete example is listed below.\n",
      "Running the example creates the model and summarizes its structure.\n",
      "We can see that the width and height of the feature maps are unchanged and that the number of feature maps was increased from 512 to double the size at 1,024.\n",
      "Now that we are familiar with how to use 1×1 filters, let’s look at some examples where they have been used in the architecture of convolutional neural network models.\n",
      "# Examples of 1×1 Filters in CNN Model Architectures\n",
      "In this section, we will highlight some important examples where 1×1 filters have been used as key elements in modern convolutional neural network model architectures.\n",
      "The 1×1 filter was perhaps first described and popularized in the 2013 paper by Min Lin, et al. in their paper titled “Network In Network.”\n",
      "In the paper, the authors propose the need for an MLP convolutional layer and the need for cross-channel pooling to promote learning across channels.\n",
      "This cascaded cross channel parametric pooling structure allows complex and learnable interactions of cross channel information.\n",
      "— Network In Network, 2013.\n",
      "They describe a 1×1 convolutional layer as a specific implementation of cross-channel parametric pooling, which, in effect, that is exactly what a 1×1 filter achieves.\n",
      "Each pooling layer performs weighted linear recombination on the input feature maps, which then go through a rectifier linear unit. […] The cross channel parametric pooling layer is also equivalent to a convolution layer with 1×1 convolution kernel.\n",
      "— Network In Network, 2013.\n",
      "The 1×1 filter was used explicitly for dimensionality reduction and for increasing the dimensionality of feature maps after pooling in the design of the inception module, used in the GoogLeNet model by Christian Szegedy, et al. in their 2014 paper titled “Going Deeper with Convolutions.”\n",
      "The paper describes an “inception module” where an input block of feature maps is processed in parallel by different convolutional layers each with differently sized filters, where a 1×1 size filter is one of the layers used.\n",
      "Example of the Naive Inception ModuleTaken from Going Deeper with Convolutions, 2014.\n",
      "The output of the parallel layers are then stacked, channel-wise, resulting in very deep stacks of convolutional layers to be processed by subsequent inception modules.\n",
      "The merging of the output of the pooling layer with the outputs of convolutional layers would lead to an inevitable increase in the number of outputs from stage to stage. Even while this architecture might cover the optimal sparse structure, it would do it very inefficiently, leading to a computational blow up within a few stages.\n",
      "— Going Deeper with Convolutions, 2014.\n",
      "The inception module is then redesigned to use 1×1 filters to reduce the number of feature maps prior to parallel convolutional layers with 5×5 and 7×7 sized filters.\n",
      "This leads to the second idea of the proposed architecture: judiciously applying dimension reductions and projections wherever the computational requirements would increase too much otherwise. […] That is, 1×1 convolutions are used to compute reductions before the expensive 3×3 and 5×5 convolutions. Besides being used as reductions, they also include the use of rectified linear activation which makes them dual-purpose\n",
      "— Going Deeper with Convolutions, 2014.\n",
      "The 1×1 filter is also used to increase the number of feature maps after pooling, artificially creating more projections of the downsampled feature map content.\n",
      "Example of the Inception Module With Dimensionality ReductionTaken from Going Deeper with Convolutions, 2014.\n",
      "The 1×1 filter was used as a projection technique to match the number of filters of input to the output of residual modules in the design of the residual network by Kaiming He, et al. in their 2015 paper titled “Deep Residual Learning for Image Recognition.”\n",
      "The authors describe an architecture comprised of “residual modules” where the input to a module is added to the output of the module in what is referred to as a shortcut connection.\n",
      "Because the input is added to the output of the module, the dimensionality must match in terms of width, height, and depth. Width and height can be maintained via padding, although a 1×1 filter is used to change the depth of the input as needed so that it can be added with the output of the module. This type of connection is referred to as a projection shortcut connection.\n",
      "Further, the residual modules use a bottleneck design with 1×1 filters to reduce the number of feature maps for computational efficiency reasons.\n",
      "The three layers are 1×1, 3×3, and 1×1 convolutions, where the 1×1 layers are responsible for reducing and then increasing (restoring) dimensions, leaving the 3×3 layer a bottleneck with smaller input/output dimensions.\n",
      "— Deep Residual Learning for Image Recognition, 2015.\n",
      "Example of a Normal and Bottleneck Residual Modules With Shortcut ConnectionsTaken from Deep Residual Learning for Image Recognition, 2015.\n",
      "# Further Reading\n",
      "This section provides more resources on the topic if you are looking to go deeper.\n",
      "- Network In Network, 2013.\n",
      "- Going Deeper with Convolutions, 2014.\n",
      "- Deep Residual Learning for Image Recognition, 2015.\n",
      "# Articles\n",
      "- One by One [ 1 x 1 ] Convolution – counter-intuitively useful, 2016.\n",
      "- Yann LeCun on No Fully Connected Layers in CNN, 2015.\n",
      "- Networks in Networks and 1×1 Convolutions, YouTube.\n",
      "# Summary\n",
      "In this tutorial, you discovered how to use 1×1 filters to control the number of feature maps in a convolutional neural network.\n",
      "Specifically, you learned:\n",
      "- The 1×1 filter can be used to create a linear projection of a stack of feature maps.\n",
      "- The projection created by a 1×1 can act like channel-wise pooling and be used for dimensionality reduction.\n",
      "- The projection created by a 1×1 can also be used directly or be used to increase the number of feature maps in a model.\n",
      "Do you have any questions?\n",
      "Ask your questions in the comments below and I will do my best to answer.\n",
      "\n",
      "- How to Layout and Manage Your Machine Learning Project\n",
      "- Using Depthwise Separable Convolutions in Tensorflow\n",
      "- Ensemble Learning Algorithm Complexity and Occam's Razor\n",
      "- A Gentle Introduction to the Bag-of-Words Model\n",
      "- A Gentle Introduction to Model Selection for Machine…\n",
      "- A Gentle Introduction to Multiple-Model Machine Learning\n"
     ]
    }
   ],
   "source": [
    "content = get_content(soup)\n",
    "print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiworkspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
