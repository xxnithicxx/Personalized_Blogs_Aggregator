Data Preparation for Variable Length Input Sequences
https://machinelearningmastery.com/data-preparation-variable-length-input-sequences-sequence-prediction/
2017-06-18
Deep learning libraries assume a vectorized representation of your data.
In the case of variable length sequence prediction problems, this requires that your data be transformed such that each sequence has the same length.
This vectorization allows code to efficiently perform the matrix operations in batch for your chosen deep learning algorithms.
In this tutorial, you will discover techniques that you can use to prepare your variable length sequence data for sequence prediction problems in Python with Keras.
After completing this tutorial, you will know:
- How to pad variable length sequences with dummy values.
- How to pad variable length sequences to a new longer desired length.
- How to truncate variable length sequences to a shorter desired length.
Kick-start your project with my new book Long Short-Term Memory Networks With Python, including step-by-step tutorials and the Python source code files for all examples.
Let’s get started.
Data Preparation for Variable-Length Input Sequences for Sequence PredictionPhoto by Adam Bautz, some rights reserved.
# Overview
This section is divided into 3 parts; they are:
- Contrived Sequence Problem
- Sequence Padding
- Sequence Truncation
This tutorial assumes you have a Python SciPy environment installed. You can use either Python 2 or 3 with this example.
This tutorial assumes you have Keras (v2.0.4+) installed with either the TensorFlow (v1.1.0+) or Theano (v0.9+) backend.
This tutorial also assumes you have scikit-learn, Pandas, NumPy, and Matplotlib installed.
If you need help setting up your Python environment, see this post:
- How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda
# Contrived Sequence Problem
We can contrive a simple sequence problem for the purposes of this tutorial.
The problem is defined as sequences of integers. There are three sequences with a length between 4 and 1 timesteps, as follows:
These can be defined as a list of lists in Python as follows (with spacing for readability):
We will use these sequences as the basis for exploring sequence padding in this tutorial.
# Sequence Padding
The pad_sequences() function in the Keras deep learning library can be used to pad variable length sequences.
The default padding value is 0.0, which is suitable for most applications, although this can be changed by specifying the preferred value via the “value” argument. For example:
The padding to be applied to the beginning or the end of the sequence, called pre- or post-sequence padding, can be specified by the “padding” argument, as follows.
Pre-sequence padding is the default (padding=’pre’)
The example below demonstrates pre-padding 3-input sequences with 0 values.
Running the example prints the 3 sequences pre-pended with zero values.

Padding can also be applied to the end of the sequences, which may be more appropriate for some problem domains.
Post-sequence padding can be specified by setting the “padding” argument to “post”.
Running the example prints the same sequences with zero-values appended.

The pad_sequences() function can also be used to pad sequences to a preferred length that may be longer than any observed sequences.
This can be done by specifying the “maxlen” argument to the desired length. Padding will then be performed on all sequences to achieve the desired length, as follows.
Running the example pads each sequence to the desired length of 5 timesteps, even though the maximum length of an observed sequence is only 4 timesteps.

# Sequence Truncation
The length of sequences can also be trimmed to a desired length.
The desired length for sequences can be specified as a number of timesteps with the “maxlen” argument.
There are two ways that sequences can be truncated: by removing timesteps from the beginning or the end of sequences.
The default truncation method is to remove timesteps from the beginning of sequences. This is called pre-sequence truncation.
The example below truncates sequences to a desired length of 2.
Running the example removes the first two timesteps from the first sequence, the first timestep from the second sequence, and pads the final sequence.

Sequences can also be trimmed by removing timesteps from the end of the sequences.
This approach may be more desirable for some problem domains.
Post-sequence truncation can be configured by changing the “truncating” argument from the default ‘pre’ to ‘post’, as follows:
Running the example removes the last two timesteps from the first sequence, the last timestep from the second sequence, and again pads the final sequence.

# Summary
In this tutorial, you discovered how to prepare variable length sequence data for use with sequence prediction problems in Python.
Specifically, you learned:
- How to pad variable length sequences with dummy values.
- How to pad out variable length sequences to a new desired length.
- How to truncate variable length sequences to a new desired length.
Do you have any questions about preparing variable length sequences?
Ask your questions in the comments and I will do my best to answer.
# Develop LSTMs for Sequence Prediction Today!
...with just a few lines of python code
Discover how in my new Ebook:
Long Short-Term Memory Networks with Python
It provides self-study tutorials on topics like:
CNN LSTMs, Encoder-Decoder LSTMs, generative models, data preparation, making predictions and much more...
Skip the Academics. Just Results.
See What's Inside

'''
1, 2, 3, 4
1, 2, 3
1
sequences = [
[1, 2, 3, 4],
[1, 2, 3],
[1]
]
pad_sequences(..., value=99)
from keras.preprocessing.sequence import pad_sequences
# define sequences
sequences = [
	[1, 2, 3, 4],
	   [1, 2, 3],
		     [1]
	]
# pad sequence
padded = pad_sequences(sequences)
print(padded)
[[1 2 3 4]
[0 1 2 3]
[0 0 0 1]
from keras.preprocessing.sequence import pad_sequences
# define sequences
sequences = [
	[1, 2, 3, 4],
	   [1, 2, 3],
		     [1]
	]
# pad sequence
padded = pad_sequences(sequences, padding='post')
print(padded)
[[1 2 3 4]
[1 2 3 0]
[1 0 0 0]]
from keras.preprocessing.sequence import pad_sequences
# define sequences
sequences = [
	[1, 2, 3, 4],
	   [1, 2, 3],
		     [1]
	]
# pad sequence
padded = pad_sequences(sequences, maxlen=5)
print(padded)
[[0 1 2 3 4]
[0 0 1 2 3]
[0 0 0 0 1]]
from keras.preprocessing.sequence import pad_sequences
# define sequences
sequences = [
	[1, 2, 3, 4],
	   [1, 2, 3],
		     [1]
	]
# truncate sequence
truncated= pad_sequences(sequences, maxlen=2)
print(truncated)
[[3 4]
[2 3]
[0 1]]
from keras.preprocessing.sequence import pad_sequences
# define sequences
sequences = [
	[1, 2, 3, 4],
	   [1, 2, 3],
		     [1]
	]
# truncate sequence
truncated= pad_sequences(sequences, maxlen=2, truncating='post')
print(truncated)
[[1 2]
[1 2]
[0 1]]
'''
