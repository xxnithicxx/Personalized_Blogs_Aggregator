A Gentle Introduction to Exploding Gradients in Neural Networks
https://machinelearningmastery.com/exploding-gradients-in-neural-networks/
2017-12-17
Exploding gradients are a problem where large error gradients accumulate and result in very large updates to neural network model weights during training.
This has the effect of your model being unstable and unable to learn from your training data.
In this post, you will discover the problem of exploding gradients with deep artificial neural networks.
After completing this post, you will know:
- What exploding gradients are and the problems they cause during training.
- How to know whether you may have exploding gradients with your network model.
- How you can fix the exploding gradient problem with your network.
Kick-start your project with my new book Long Short-Term Memory Networks With Python, including step-by-step tutorials and the Python source code files for all examples.
Let’s get started.
- Update Oct/2018: Removed mention of ReLU as a solution.
A Gentle Introduction to Exploding Gradients in Recurrent Neural NetworksPhoto by Taro Taylor, some rights reserved.
# What Are Exploding Gradients?
An error gradient is the direction and magnitude calculated during the training of a neural network that is used to update the network weights in the right direction and by the right amount.
In deep networks or recurrent neural networks, error gradients can accumulate during an update and result in very large gradients. These in turn result in large updates to the network weights, and in turn, an unstable network. At an extreme, the values of weights can become so large as to overflow and result in NaN values.
The explosion occurs through exponential growth by repeatedly multiplying gradients through the network layers that have values larger than 1.0.
# What Is the Problem with Exploding Gradients?
In deep multilayer Perceptron networks, exploding gradients can result in an unstable network that at best cannot learn from the training data and at worst results in NaN weight values that can no longer be updated.
… exploding gradients can make learning unstable.
— Page 282, Deep Learning, 2016.
In recurrent neural networks, exploding gradients can result in an unstable network that is unable to learn from training data and at best a network that cannot learn over long input sequences of data.
… the exploding gradients problem refers to the large increase in the norm of the gradient during training. Such events are due to the explosion of the long term components
— On the difficulty of training recurrent neural networks, 2013.
# How do You Know if You Have Exploding Gradients?
There are some subtle signs that you may be suffering from exploding gradients during the training of your network, such as:
- The model is unable to get traction on your training data (e.g. poor loss).
- The model is unstable, resulting in large changes in loss from update to update.
- The model loss goes to NaN during training.
If you have these types of problems, you can dig deeper to see if you have a problem with exploding gradients.
There are some less subtle signs that you can use to confirm that you have exploding gradients.
- The model weights quickly become very large during training.
- The model weights go to NaN values during training.
- The error gradient values are consistently above 1.0 for each node and layer during training.
# How to Fix Exploding Gradients?
There are many approaches to addressing exploding gradients; this section lists some best practice approaches that you can use.
In deep neural networks, exploding gradients may be addressed by redesigning the network to have fewer layers.
There may also be some benefit in using a smaller batch size while training the network.
In recurrent neural networks, updating across fewer prior time steps during training, called truncated Backpropagation through time, may reduce the exploding gradient problem.
In recurrent neural networks, gradient exploding can occur given the inherent instability in the training of this type of network, e.g. via Backpropagation through time that essentially transforms the recurrent network into a deep multilayer Perceptron neural network.
Exploding gradients can be reduced by using the Long Short-Term Memory (LSTM) memory units and perhaps related gated-type neuron structures.
Adopting LSTM memory units is a new best practice for recurrent neural networks for sequence prediction.
Exploding gradients can still occur in very deep Multilayer Perceptron networks with a large batch size and LSTMs with very long input sequence lengths.
If exploding gradients are still occurring, you can check for and limit the size of gradients during the training of your network.
This is called gradient clipping.
Dealing with the exploding gradients has a simple but very effective solution: clipping gradients if their norm exceeds a given threshold.
— Section 5.2.4, Vanishing and Exploding Gradients, Neural Network Methods in Natural Language Processing, 2017.
Specifically, the values of the error gradient are checked against a threshold value and clipped or set to that threshold value if the error gradient exceeds the threshold.
To some extent, the exploding gradient problem can be mitigated by gradient clipping (thresholding the values of the gradients before performing a gradient descent step).
— Page 294, Deep Learning, 2016.
In the Keras deep learning library, you can use gradient clipping by setting the clipnorm or clipvalue arguments on your optimizer before training.
Good default values are clipnorm=1.0 and clipvalue=0.5.
- Usage of optimizers in the Keras API
Another approach, if exploding gradients are still occurring, is to check the size of network weights and apply a penalty to the networks loss function for large weight values.
This is called weight regularization and often an L1 (absolute weights) or an L2 (squared weights) penalty can be used.
Using an L1 or L2 penalty on the recurrent weights can help with exploding gradients
— On the difficulty of training recurrent neural networks, 2013.
In the Keras deep learning library, you can use weight regularization by setting the kernel_regularizer argument on your layer and using an L1 or L2 regularizer.
- Usage of regularizers in the Keras API
# Further Reading
This section provides more resources on the topic if you are looking to go deeper.
- How to Fix Vanishing Gradients Using the Rectified Linear Activation Unit (ReLU)
- Deep Learning, 2016.
- Neural Network Methods in Natural Language Processing, 2017.
- On the difficulty of training recurrent neural networks, 2013.
- Learning long-term dependencies with gradient descent is difficult, 1994.
- Understanding the exploding gradient problem, 2012.
- Why is it a problem to have exploding gradients in a neural net (especially in an RNN)?
- How does LSTM help prevent the vanishing (and exploding) gradient problem in a recurrent neural network?
- Rectifier (neural networks)
- Usage of optimizers in the Keras API
- Usage of regularizers in the Keras API
# Summary
In this post, you discovered the problem of exploding gradients when training deep neural network models.
Specifically, you learned:
- What exploding gradients are and the problems they cause during training.
- How to know whether you may have exploding gradients with your network model.
- How you can fix the exploding gradient problem with your network.
Do you have any questions?
Ask your questions in the comments below and I will do my best to answer.
# Develop LSTMs for Sequence Prediction Today!
...with just a few lines of python code
Discover how in my new Ebook:
Long Short-Term Memory Networks with Python
It provides self-study tutorials on topics like:
CNN LSTMs, Encoder-Decoder LSTMs, generative models, data preparation, making predictions and much more...
Skip the Academics. Just Results.
See What's Inside

'''

'''
