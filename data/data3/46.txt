Linear Classification in R
https://machinelearningmastery.com/linear-classification-in-r/
2014-08-07
In this post you will discover recipes for 3 linear classification algorithms in R.
All recipes in this post use the iris flowers dataset provided with R in the datasets package. The dataset describes the measurements if iris flowers and requires classification of each observation to one of three flower species.
Kick-start your project with my new book Machine Learning Mastery With R, including step-by-step tutorials and the R source code files for all examples.
Let’s get started.
Red vs BluePhoto by Robert Couse-Baker, some rights reserved
# Logistic Regression
Logistic Regression is a classification method that models the probability of an observation belonging to one of two classes. As such, normally logistic regression is demonstrated with binary classification problem (2 classes). Logistic Regression can also be used on problems with more than two classes (multinomial), as in this case.
This recipe demonstrates multinomial logistic regression method on the iris dataset.
Learn more about the vglm function in the VGAM package.




# Linear Discriminant Analysis
LDA is a classification method that finds a linear combination of data attributes that best separate the data into classes.
This recipes demonstrates the LDA method on the iris dataset.
Learn more about the lda function the MASS package.
# Partial Least Squares Discriminant Analysis
Partial Least Squares Discriminate Analysis is the application of LDA on a dimension-reducing projection of the input data (partial least squares).
This recipe demonstrates the PLSDA method on the iris dataset.
Learn more about the plsda function in the caret package.
# Summary
In this post, you discovered 3 recipes for linear classification that you can copy and paste into your own problem.
# Discover Faster Machine Learning in R!
...with just a few lines of R code
Discover how in my new Ebook:
Machine Learning Mastery With R
Covers self-study tutorials and end-to-end projects like:
Loading data, visualization, build models, tuning, and much more...
Skip the Academics. Just Results.
See What's Inside

'''
# load the package
library(VGAM)
# load data
data(iris)
# fit model
fit <- vglm(Species~., family=multinomial, data=iris)
# summarize the fit
summary(fit)
# make predictions
probabilities <- predict(fit, iris[,1:4], type="response")
predictions <- apply(probabilities, 1, which.max)
predictions[which(predictions=="1")] <- levels(iris$Species)[1]
predictions[which(predictions=="2")] <- levels(iris$Species)[2]
predictions[which(predictions=="3")] <- levels(iris$Species)[3]
# summarize accuracy
table(predictions, iris$Species)
# load the package
library(MASS)
data(iris)
# fit model
fit <- lda(Species~., data=iris)
# summarize the fit
summary(fit)
# make predictions
predictions <- predict(fit, iris[,1:4])$class
# summarize accuracy
table(predictions, iris$Species)
# load the package
library(caret)
data(iris)
x <- iris[,1:4]
y <- iris[,5]
# fit model
fit <- plsda(x, y, probMethod="Bayes")
# summarize the fit
summary(fit)
# make predictions
predictions <- predict(fit, iris[,1:4])
# summarize accuracy
table(predictions, iris$Species)
'''
