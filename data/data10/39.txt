A Gentle Introduction to Vectors for Machine Learning
https://machinelearningmastery.com/gentle-introduction-vectors-machine-learning/
2018-02-01
Vectors are a foundational element of linear algebra.
Vectors are used throughout the field of machine learning in the description of algorithms and processes such as the target variable (y) when training an algorithm.
In this tutorial, you will discover linear algebra vectors for machine learning.
After completing this tutorial, you will know:
- What a vector is and how to define one in Python with NumPy.
- How to perform vector arithmetic such as addition, subtraction, multiplication and division.
- How to perform additional operations such as dot product and multiplication with a scalar.
Kick-start your project with my new book Linear Algebra for Machine Learning, including step-by-step tutorials and the Python source code files for all examples.
Let’s get started.
A Gentle Introduction to Vectors for Machine LearningPhoto by Lachlan Donald, some rights reserved.
# Tutorial Overview
This tutorial is divided into 5 parts; they are:
- What is a Vector?
- Defining a Vector
- Vector Arithmetic
- Vector Dot Product
- Vector-Scalar Multiplication




# What is a Vector?
A vector is a tuple of one or more values called scalars.
Vectors are built from components, which are ordinary numbers. You can think of a vector as a list of numbers, and vector algebra as operations performed on the numbers in the list.
— Page 69, No Bullshit Guide To Linear Algebra, 2017
Vectors are often represented using a lowercase character such as “v”; for example:
Where v1, v2, v3 are scalar values, often real values.
Vectors are also shown using a vertical representation or a column; for example:
It is common to represent the target variable as a vector with the lowercase “y” when describing the training of a machine learning algorithm.
It is common to introduce vectors using a geometric analogy, where a vector represents a point or coordinate in an n-dimensional space, where n is the number of dimensions, such as 2.
The vector can also be thought of as a line from the origin of the vector space with a direction and a magnitude.
These analogies are good as a starting point, but should not be held too tightly as we often consider very high dimensional vectors in machine learning. I find the vector-as-coordinate the most compelling analogy in machine learning.
Now that we know what a vector is, let’s look at how to define a vector in Python.
# Defining a Vector
We can represent a vector in Python as a NumPy array.
A NumPy array can be created from a list of numbers. For example, below we define a vector with the length of 3 and the integer values 1, 2 and 3.
The example defines a vector with 3 elements.
Running the example prints the defined vector.

# Vector Arithmetic
In this section will demonstrate simple vector-vector arithmetic, where all operations are performed element-wise between two vectors of equal length to result in a new vector with the same length
Two vectors of equal length can be added together to create a new third vector.
The new vector has the same length as the other two vectors. Each element of the new vector is calculated as the addition of the elements of the other vectors at the same index; for example:
Or, put another way:
We can add vectors directly in Python by adding NumPy arrays.
The example defines two vectors with three elements each, then adds them together.
Running the example first prints the two parent vectors then prints a new vector that is the addition of the two vectors.

One vector can be subtracted from another vector of equal length to create a new third vector.
As with addition, the new vector has the same length as the parent vectors and each element of the new vector is calculated as the subtraction of the elements at the same indices.
Or, put another way:
The NumPy arrays can be directly subtracted in Python.
The example defines two vectors with three elements each, then subtracts the first from the second.
Running the example first prints the two parent vectors then prints the new vector that is the first minus the second.

Two vectors of equal length can be multiplied together.
As with addition and subtraction, this operation is performed element-wise to result in a new vector of the same length.
or
Or, put another way:
We can perform this operation directly in NumPy.
The example defines two vectors with three elements each, then multiplies the vectors together.
Running the example first prints the two parent vectors, then the new vector is printed.

Two vectors of equal length can be divided.
As with other arithmetic operations, this operation is performed element-wise to result in a new vector of the same length.
or
Or, put another way:
We can perform this operation directly in NumPy.
The example defines two vectors with three elements each, then divides the first by the second.
Running the example first prints the two parent vectors, followed by the result of the vector division.

# Vector Dot Product
We can calculate the sum of the multiplied elements of two vectors of the same length to give a scalar.
This is called the dot product, named because of the dot operator used when describing the operation.
The dot product is the key tool for calculating vector projections, vector decompositions, and determining orthogonality. The name dot product comes from the symbol used to denote it.
— Page 110, No Bullshit Guide To Linear Algebra, 2017
The operation can be used in machine learning to calculate the weighted sum of a vector.
The dot product is calculated as follows:
or
We can calculate the dot product between two vectors in Python using the dot() function on a NumPy array. It can also be calculated using the newer @ operator, since Python version 3.5. The example below demonstrates both methods.
The example defines two vectors with three elements each, then calculates the dot product.
Running the example first prints the two parent vectors, then the scalar dot product.

# Vector-Scalar Multiplication
A vector can be multiplied by a scalar, in effect scaling the magnitude of the vector.
To keep notation simple, we will use lowercase “s” to represent the scalar value.
or
The multiplication is performed on each element of the vector to result in a new scaled vector of the same length.
Or, put another way:
We can perform this operation directly with the NumPy array.
The example first defines the vector and the scalar then multiplies the vector by the scalar.
Running the example first prints the parent vector, then scalar, and then the result of multiplying the two together.
Similarly, vector-scalar addition, subtraction, and division can be performed in the same way.
# Extensions
This section lists some ideas for extending the tutorial that you may wish to explore.
- Create 5 examples using each operation using your own data.
- Implement each vector operation manually for vectors defined as lists.
- Search machine learning papers and find 1 example of each operation being used.
If you explore any of these extensions, I’d love to know.
# Further Reading
This section provides more resources on the topic if you are looking to go deeper.
- Section 1.15, Vectors. No Bullshit Guide To Linear Algebra, 2017.
- Section 2.2, Vector operations. No Bullshit Guide To Linear Algebra, 2017.
- Introduction to Linear Algebra, 2016.
- Chapter 2, Linear Algebra, Deep Learning, 2016.
- numpy.array() API
- numpy.dot() API
- Vector space on Wikipedia
- Dot product on Wikipedia
# Summary
In this tutorial, you discovered linear algebra vectors for machine learning.
Specifically, you learned:
- What a vector is and how to define one in Python with NumPy.
- How to perform vector arithmetic such as addition, subtraction, multiplication and division.
- How to perform additional operations such as dot product and multiplication with a scalar.
Do you have any questions?
Ask your questions in the comments below and I will do my best to answer.
# Get a Handle on Linear Algebra for Machine Learning!
...by writing lines of code in python
Discover how in my new Ebook:
Linear Algebra for Machine Learning
It provides self-study tutorials on topics like:
Vector Norms, Matrix Multiplication, Tensors, Eigendecomposition, SVD, PCA and much more...
Skip the Academics. Just Results.
See What's Inside

'''
v = (v1, v2, v3)
      v1
v = ( v2 )
      v3
# create a vector
from numpy import array
v = array([1, 2, 3])
print(v)
[1 2 3]
c = a + b
a + b = (a1 + b1, a2 + b2, a3 + b3)
c[0] = a[0] + b[0]
c[1] = a[1] + b[1]
c[2] = a[2] + b[2]
# add vectors
from numpy import array
a = array([1, 2, 3])
print(a)
b = array([1, 2, 3])
print(b)
c = a + b
print(c)
[1 2 3]

[1 2 3]

[2 4 6]
c = a - b
a - b = (a1 - b1, a2 - b2, a3 - b3)
c[0] = a[0] - b[0]
c[1] = a[1] - b[1]
c[2] = a[2] - b[2]
# subtract vectors
from numpy import array
a = array([1, 2, 3])
print(a)
b = array([0.5, 0.5, 0.5])
print(b)
c = a - b
print(c)
[1 2 3]

[ 0.5 0.5 0.5]

[ 0.5 1.5 2.5]
c = a * b
a * b = (a1 * b1, a2 * b2, a3 * b3)
ab = (a1b1, a2b2, a3b3)
c[0] = a[0] * b[0]
c[1] = a[1] * b[1]
c[2] = a[2] * b[2]
# multiply vectors
from numpy import array
a = array([1, 2, 3])
print(a)
b = array([1, 2, 3])
print(b)
c = a * b
print(c)
[1 2 3]

[1 2 3]

[1 4 9]
c = a / b
a / b = (a1 / b1, a2 / b2, a3 / b3)
a / b = (a1b1, a2b2, a3b3)
c[0] = a[0] / b[0]
c[1] = a[1] / b[1]
c[2] = a[2] / b[2]
# divide vectors
from numpy import array
a = array([1, 2, 3])
print(a)
b = array([1, 2, 3])
print(b)
c = a / b
print(c)
[1 2 3]

[1 2 3]

[ 1. 1. 1.]
c = a . b
a . b = (a1 * b1 + a2 * b2 + a3 * b3)
a . b = (a1b1 + a2b2 + a3b3)
# dot product vectors
from numpy import array
a = array([1, 2, 3])
print(a)
b = array([1, 2, 3])
print(b)
c = a.dot(b)
print(c)
d = a @ b
print(d)
[1 2 3]

[1 2 3]

14

14
c = s * v
c = sv
s * v = (s * v1, s * v2, s * v3)
c[0] = a[0] * s
c[1] = a[1] * s
c[2] = a[2] * s
# vector-scalar multiplication
from numpy import array
a = array([1, 2, 3])
print(a)
s = 0.5
print(s)
c = s * a
print(c)
[1 2 3]

0.5

[ 0.5 1. 1.5]
'''
